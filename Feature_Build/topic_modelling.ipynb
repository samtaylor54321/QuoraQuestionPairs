{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0e7f1eca6087c4c45c31bc6045dea57a3f37b89f"
   },
   "source": [
    "# Topic modelling and entity extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Usual imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import concurrent.futures\n",
    "import time\n",
    "import pyLDAvis.sklearn\n",
    "from pylab import bone, pcolor, colorbar, plot, show, rcParams, savefig\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "# Plotly based imports for visualization\n",
    "from plotly import tools\n",
    "import plotly.plotly as py\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# spaCy based imports\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_AND_TOKENIZE = True\n",
    "\n",
    "INPUT_PATH = os.path.join(os.pardir, 'Datasets')\n",
    "OUT_PATH = os.path.join(os.pardir, 'Datasets')\n",
    "INPUT_FILE = 'train.csv'\n",
    "SAMPLE_SIZE = 50000\n",
    "\n",
    "NUM_TOPICS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtype = INPUT_FILE.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "d57d08400a530b786ad3226110e34aefb85e94b1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid1  qid2                                          question1  \\\n",
       "id                                                                  \n",
       "0      1     2  What is the step by step guide to invest in sh...   \n",
       "1      3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2      5     6  How can I increase the speed of my internet co...   \n",
       "3      7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4      9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                            question2  is_duplicate  \n",
       "id                                                                   \n",
       "0   What is the step by step guide to invest in sh...             0  \n",
       "1   What would happen if the Indian government sto...             0  \n",
       "2   How can Internet speed be increased by hacking...             0  \n",
       "3   Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4             Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "df = pd.read_csv(os.path.join(INPUT_PATH, INPUT_FILE), nrows=SAMPLE_SIZE)\n",
    "df.set_index('id', inplace=True)\n",
    "df.fillna('Empty question', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation\n",
    "stopwords = list(STOP_WORDS)\n",
    "parser = English()\n",
    "def spacy_tokenizer(sentence):\n",
    "    mytokens = parser(sentence)\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "    mytokens = [ word for word in mytokens if word not in stopwords and word not in punctuations ]\n",
    "    mytokens = \" \".join([i for i in mytokens])\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_AND_TOKENIZE:\n",
    "    df['question1'] = df['question1'].apply(spacy_tokenizer)\n",
    "    df['question2'] = df['question2'].apply(spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Entity Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "17fe81e7e90dfb32681f56a03b9136bbb74343b8"
   },
   "outputs": [],
   "source": [
    "# Creating a spaCy object\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "677e753450ddea24b1289e3033a2f7928710ef25"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">associate product manager apm program \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    early 20s\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " join learn product management reward career company</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ex = nlp(df['question1'][98])\n",
    "spacy.displacy.render(ex, style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(x):\n",
    "    entity_types = (\n",
    "        'PERSON',\n",
    "        'NORP',\n",
    "        'FAC',\n",
    "        'ORG',\n",
    "        'GPE',\n",
    "        'LOC',\n",
    "        'PRODUCT',\n",
    "        'EVENT',\n",
    "        'WORK_OF_ART',\n",
    "        'LAW',\n",
    "        'LANGUAGE',\n",
    "        'DATE',\n",
    "        'TIME',\n",
    "        'PERCENT',\n",
    "        'MONEY',\n",
    "        'QUANTITY',\n",
    "        'ORDINAL',\n",
    "        'CARDINAL'\n",
    "    )\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        data=np.zeros([len(x), len(entity_types)]).astype(int),\n",
    "        columns=entity_types,\n",
    "        index=x.index\n",
    "    )\n",
    "    for i, val in x.iteritems():\n",
    "        if i % (len(x) / 10) == 0:\n",
    "            print('Entry {}/{}'.format(i, len(x)))\n",
    "        doc = nlp(spacy_tokenizer(val), disable=['parser'])\n",
    "        for ent in doc.ents:\n",
    "            df.loc[i, ent.label_] += 1\n",
    "    df.columns = [col + '_COUNT' for col in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry 0/50000\n",
      "Entry 5000/50000\n",
      "Entry 10000/50000\n",
      "Entry 15000/50000\n",
      "Entry 20000/50000\n",
      "Entry 25000/50000\n"
     ]
    }
   ],
   "source": [
    "ents_df_1 = get_entities(df['question1'])\n",
    "ents_df_2 = get_entities(df['question2'])\n",
    "ents_diff = ents_df_1 - ents_df_2\n",
    "assert ents_diff.index.nunique() == len(ents_diff), 'Index not unique'\n",
    "ents_diff.to_csv(os.path.join(OUT_PATH, 'FEATURE_entity_counts_{}.csv'.format(runtype)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8cd922f8229f6aba3f08dfb25d8793a5e2b0ee57"
   },
   "source": [
    "## Parts of Speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a8ed2a71e2d90ad317e7b0d69d0e6544ff19f17c"
   },
   "outputs": [],
   "source": [
    "# # POS tagging\n",
    "# for i in nlp(review):\n",
    "#     print(i,\"=>\",i.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e64d8d97ef7443b594431dc4662450264460aae1"
   },
   "source": [
    "## Topic-modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fd00ec3f6d99df6434671334c513511485de5a18"
   },
   "outputs": [],
   "source": [
    "# Creating a vectorizer\n",
    "vectorizer = CountVectorizer(\n",
    "    min_df=5, \n",
    "    max_df=0.9, \n",
    "    stop_words='english', \n",
    "    lowercase=True, \n",
    "    token_pattern='[a-zA-Z\\-][a-zA-Z\\-]{2,}'\n",
    ")\n",
    "corpus = pd.concat([df['question1'], df['question2']])\n",
    "vectorized_corpus = vectorizer.fit_transform(corpus)\n",
    "q1_vectorized = vectorizer.transform(df['question1'])\n",
    "q2_vectorized = vectorizer.transform(df['question2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f0140ca0b3eb106edeee8afac1720e25eae5675"
   },
   "outputs": [],
   "source": [
    "# Latent Dirichlet Allocation Model\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=NUM_TOPICS, \n",
    "    max_iter=10, \n",
    "    verbose=True,\n",
    "    random_state=0\n",
    ")\n",
    "if runtype == 'train':\n",
    "    lda.fit(vectorized_corpus)\n",
    "    pickle.dump(lda, open('lda_model.pkl', 'wb'))\n",
    "else:\n",
    "    pickle.load(open('lda_model.pkl', 'rb')) \n",
    "q1_lda = lda.transform(q1_vectorized)\n",
    "q2_lda = lda.transform(q2_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_similarity = q1_lda * q2_lda\n",
    "topic_df = pd.DataFrame(\n",
    "    data=topic_similarity,\n",
    "    columns=['PROB_BOTH_SHARE_TOPIC_' + str(i) for i in range(topic_similarity.shape[1])],\n",
    "    index=df.index\n",
    ")\n",
    "topic_df.to_csv(os.path.join(OUT_PATH, 'FEATURE_topic_sharing_{}.csv'.format(runtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4965ca621bdd6abcf8dd4eb1a41699603cfa2284",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Functions for printing keywords for each topic\n",
    "def selected_topics(model, vectorizer, top_n=10):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-top_n - 1:-1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9a9f1099afa5c6c98ca90103080aa397cd146d3c"
   },
   "outputs": [],
   "source": [
    "# Keywords for topics clustered by Latent Dirichlet Allocation\n",
    "print(\"LDA Model:\")\n",
    "selected_topics(lda, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1a9eeef90515577592dfebab1635c1f77a7a6868"
   },
   "source": [
    "The index in the above list with the largest value represents the most dominant topic for the given review.\n",
    "\n",
    "\n",
    "# Visualizing LDA results with pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "520045555b8cd5ebf89634e580a23f8a221e34c1"
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "dash = pyLDAvis.sklearn.prepare(lda, q1_vectorized, vectorizer, mds='tsne')\n",
    "dash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bb464a9c9c42de1d31dc0bcf4e850cea40af468c"
   },
   "source": [
    "## How to interpret this graph?\n",
    "1. Topics on the left while their respective keywords are on the right.\n",
    "2. Larger topics are more frequent and closer the topics, mor the similarity\n",
    "3. Selection of keywords is based on their frequency and discriminancy.\n",
    "\n",
    "**Hover over the topics on the left to get information about their keywords on the right.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
