{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature: Out-Of-Fold Predictions from a Siamese LSTM with Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This utility package imports `numpy`, `pandas`, `matplotlib` and a helper `kg` module into the root namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import string\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import *\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = os.path.join(os.pardir, 'Datasets')\n",
    "OUT_PATH = os.path.join(os.pardir, 'Datasets')\n",
    "TRAIN_FILE = 'train.csv'\n",
    "TEST_FILE = 'test.csv'\n",
    "SAMPLE_SIZE = None\n",
    "\n",
    "EMBEDDING_DIMENSIONS = 10\n",
    "NUM_FOLDS = 2\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation\n",
    "stopwords = list(STOP_WORDS)\n",
    "parser = English()\n",
    "def spacy_tokenizer(sentence):\n",
    "    mytokens = parser(sentence)\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "    mytokens = [ word for word in mytokens if word not in stopwords and word not in punctuations ]\n",
    "    mytokens = \" \".join([i for i in mytokens])\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>15738</td>\n",
       "      <td>15739</td>\n",
       "      <td>play pokémon korea</td>\n",
       "      <td>play pokémon china</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>12736</td>\n",
       "      <td>104117</td>\n",
       "      <td>dish crab cake</td>\n",
       "      <td>good dish buffalo chicken</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>121486</td>\n",
       "      <td>121487</td>\n",
       "      <td>advisable material crash test automobile ducti...</td>\n",
       "      <td>server setup buddypress</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>254474</td>\n",
       "      <td>258192</td>\n",
       "      <td>improve logical programme skill</td>\n",
       "      <td>improve logical skill programme</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>48103</td>\n",
       "      <td>3062</td>\n",
       "      <td>close 3rd world war</td>\n",
       "      <td>close world war iii</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          qid1    qid2                                          question1  \\\n",
       "id                                                                          \n",
       "8067     15738   15739                                 play pokémon korea   \n",
       "368101   12736  104117                                     dish crab cake   \n",
       "70497   121486  121487  advisable material crash test automobile ducti...   \n",
       "226567  254474  258192                    improve logical programme skill   \n",
       "73186    48103    3062                                close 3rd world war   \n",
       "\n",
       "                              question2  is_duplicate  \n",
       "id                                                     \n",
       "8067                 play pokémon china             0  \n",
       "368101        good dish buffalo chicken             0  \n",
       "70497           server setup buddypress             0  \n",
       "226567  improve logical skill programme             1  \n",
       "73186               close world war iii             1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "# df = pd.read_csv(os.path.join(INPUT_PATH, TRAIN_FILE), nrows=SAMPLE_SIZE)\n",
    "# df.set_index('id', inplace=True)\n",
    "# df.fillna('Empty question', inplace=True)\n",
    "# df['question1'] = df['question1'].apply(spacy_tokenizer)\n",
    "# df['question2'] = df['question2'].apply(spacy_tokenizer)\n",
    "df = pickle.load(open('tokenized_train.csv', 'rb'))\n",
    "df = df.sample(200000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doe surface pro 4 compare ipad pro</td>\n",
       "      <td>microsoft choose core m3 core i3 home surface ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hair transplant age 24 cost</td>\n",
       "      <td>cost doe hair transplant require</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>way send money china</td>\n",
       "      <td>send money china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>food emulsifier</td>\n",
       "      <td>food fibre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aberystwyth start read</td>\n",
       "      <td>start read</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  question1  \\\n",
       "test_id                                       \n",
       "0        doe surface pro 4 compare ipad pro   \n",
       "1               hair transplant age 24 cost   \n",
       "2                      way send money china   \n",
       "3                           food emulsifier   \n",
       "4                    aberystwyth start read   \n",
       "\n",
       "                                                 question2  \n",
       "test_id                                                     \n",
       "0        microsoft choose core m3 core i3 home surface ...  \n",
       "1                         cost doe hair transplant require  \n",
       "2                                         send money china  \n",
       "3                                               food fibre  \n",
       "4                                               start read  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "# test_df = pd.read_csv(os.path.join(INPUT_PATH, TEST_FILE), nrows=SAMPLE_SIZE)\n",
    "# test_df.set_index('test_id', inplace=True)\n",
    "# test_df.fillna('Empty question', inplace=True)\n",
    "# test_df['question1'] = test_df['question1'].apply(spacy_tokenizer)\n",
    "# test_df['question2'] = test_df['question2'].apply(spacy_tokenizer)\n",
    "test_df = pickle.load(open('tokenized_test.csv', 'rb'))\n",
    "test_df = test_df.iloc[:2345796, :]\n",
    "#test_df = test_df.sample(1000)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embedding\n",
    "\n",
    "Word embedding lookup matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.concat([df['question1'], df['question2']])\n",
    "w2v_model = Word2Vec(\n",
    "    corpus.str.split(' ').tolist(), \n",
    "    size=EMBEDDING_DIMENSIONS, \n",
    "    window=5, \n",
    "    min_count=1, \n",
    ")\n",
    "pickle.dump(w2v_model, open('gensim_w2v_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output vectors\n",
    "# wv = w2v_model.wv\n",
    "# q1_w2v_vec_df = pd.DataFrame(\n",
    "#     data=np.zeros([len(df), EMBEDDING_DIMENSIONS]), \n",
    "#     index=df.index,\n",
    "#     columns=['Q1_GENSIM_EMB_{}'.format(str(i)) for i in range(EMBEDDING_DIMENSIONS)]\n",
    "# )\n",
    "# q2_w2v_vec_df = pd.DataFrame(\n",
    "#     data=np.zeros([len(df), EMBEDDING_DIMENSIONS]), \n",
    "#     index=df.index,\n",
    "#     columns=['Q2_GENSIM_EMB_{}'.format(str(i)) for i in range(EMBEDDING_DIMENSIONS)]\n",
    "# )\n",
    "# for i, row in df.iterrows():\n",
    "#     if i % (len(df) / 10) == 0:\n",
    "#         print('Entry {}/{}'.format(i, len(df)))\n",
    "#     for token in row['question1'].split(' '):\n",
    "#         q1_w2v_vec_df.loc[i, :] += wv[token]\n",
    "#     for token in row['question2'].split(' '):\n",
    "#         q2_w2v_vec_df.loc[i, :] += wv[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = w2v_model.wv.get_keras_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_matrix = kg.io.load(project.aux_dir + 'fasttext_vocab_embedding_matrix.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word sequences\n",
    "\n",
    "Padded sequences of word indices for every question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_string_length = corpus.str.split(' ').apply(len).max()\n",
    "pickle.dump(max_string_length, open('max_question_length.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padded_index_sequence(array_of_word_lists, word2vec_model, padding_index, pad_length):\n",
    "    source_word_indices = []\n",
    "    for i in range(len(array_of_word_lists)):\n",
    "        source_word_indices.append([])\n",
    "        for j in range(len(array_of_word_lists[i])):\n",
    "            if j >= pad_length:\n",
    "                break\n",
    "            word = array_of_word_lists[i][j]\n",
    "            if word in word2vec_model.wv.vocab:\n",
    "                word_index = word2vec_model.wv.vocab[word].index\n",
    "                source_word_indices[i].append(word_index)\n",
    "            else:\n",
    "                # Do something. For example, leave it blank or replace with padding character's index.\n",
    "                source_word_indices[i].append(padding_index)\n",
    "        while len(source_word_indices[i]) < pad_length:\n",
    "            source_word_indices[i].append(padding_index)\n",
    "    return np.array(source_word_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_q1 = get_padded_index_sequence(\n",
    "    df['question1'].str.split(' ').tolist(), \n",
    "    w2v_model, \n",
    "    0, \n",
    "    max_string_length\n",
    ")\n",
    "X_train_q2 = get_padded_index_sequence(\n",
    "    df['question2'].str.split(' ').tolist(), \n",
    "    w2v_model, \n",
    "    0, \n",
    "    max_string_length\n",
    ")\n",
    "X_test_q1 = get_padded_index_sequence(\n",
    "    test_df['question1'].str.split(' ').tolist(), \n",
    "    w2v_model, \n",
    "    0, \n",
    "    max_string_length\n",
    ")\n",
    "X_test_q2 = get_padded_index_sequence(\n",
    "    test_df['question2'].str.split(' ').tolist(), \n",
    "    w2v_model, \n",
    "    0, \n",
    "    max_string_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "200000\n",
      "2345796\n",
      "2345796\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_q1))\n",
    "print(len(X_train_q2))\n",
    "print(len(X_test_q1))\n",
    "print(len(X_test_q2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_q1 = kg.io.load(project.preprocessed_data_dir + 'sequences_q1_fasttext_train.pickle')\n",
    "#X_train_q2 = kg.io.load(project.preprocessed_data_dir + 'sequences_q2_fasttext_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_q1 = kg.io.load(project.preprocessed_data_dir + 'sequences_q1_fasttext_test.pickle')\n",
    "#X_test_q2 = kg.io.load(project.preprocessed_data_dir + 'sequences_q2_fasttext_test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df['is_duplicate'].values #kg.io.load(project.features_dir + 'y_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df, test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embedding properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDDING_DIM = embedding_matrix.shape[-1]\n",
    "# VOCAB_LENGTH = embedding_matrix.shape[0]\n",
    "MAX_SEQUENCE_LENGTH = max_string_length  # X_train_q1.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \"\"\"    \n",
    "    margin = 1\n",
    "    return K.mean((1 - y_true) * K.square(y_pred) +\n",
    "                   y_true * K.square(K.maximum(margin - y_pred, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    \n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\" by using a context\n",
    "    vector to assist the attention.\n",
    "    \n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    \n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, init='glorot_uniform',\n",
    "                 kernel_regularizer=None, bias_regularizer=None,\n",
    "                 kernel_constraint=None, bias_constraint=None,  **kwargs):\n",
    "        \n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get(init)\n",
    "        self.kernel_initializer = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            (input_shape[-1], 1),\n",
    "            initializer=self.kernel_initializer,\n",
    "            name='{}_W'.format(self.name),\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            (input_shape[1],),\n",
    "            initializer='zero',\n",
    "            name='{}_b'.format(self.name),\n",
    "            regularizer=self.bias_regularizer,\n",
    "            constraint=self.bias_constraint\n",
    "        )\n",
    "        self.u = self.add_weight(\n",
    "            (input_shape[1],),\n",
    "            initializer=self.kernel_initializer,\n",
    "            name='{}_u'.format(self.name),\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint\n",
    "        )\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, mask):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        multdata = K.dot(x, self.kernel)     # (x, 40, 300) * (300, 1) => (x, 40, 1)\n",
    "        multdata = K.squeeze(multdata, -1)   # (x, 40)\n",
    "        multdata = multdata + self.b         # (x, 40) + (40,)\n",
    "\n",
    "        multdata = K.tanh(multdata)          # (x, 40)\n",
    "\n",
    "        multdata = multdata * self.u         # (x, 40) * (40, 1) => (x, 1)\n",
    "        multdata = K.exp(multdata)           # (x, 1)\n",
    "\n",
    "        # Apply mask after the exp. will be re-normalized next.\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())  # (x, 40)\n",
    "            multdata = mask * multdata       # (x, 40) * (x, 40, )\n",
    "\n",
    "        # In some cases, especially in the early stages of training, the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        multdata /= K.cast(K.sum(multdata, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        multdata = K.expand_dims(multdata)\n",
    "        weighted_input = x * multdata\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(params):\n",
    "#     embedding_layer = Embedding(\n",
    "#         VOCAB_LENGTH,\n",
    "#         EMBEDDING_DIM,\n",
    "#         weights=[embedding_matrix],\n",
    "#         input_length=MAX_SEQUENCE_LENGTH,\n",
    "#         trainable=False,\n",
    "#     )\n",
    "    lstm_layer = LSTM(\n",
    "        params['num_lstm'],\n",
    "        dropout=params['lstm_dropout_rate'],\n",
    "        recurrent_dropout=params['lstm_dropout_rate'],\n",
    "        return_sequences=True,\n",
    "    )\n",
    "    attention_layer = AttentionWithContext()\n",
    "\n",
    "    sequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
    "    x1 = attention_layer(lstm_layer(embedded_sequences_1))\n",
    "\n",
    "    sequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
    "    y1 = attention_layer(lstm_layer(embedded_sequences_2))\n",
    "\n",
    "    merged = concatenate([x1, y1])\n",
    "    merged = Dropout(params['dense_dropout_rate'])(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "\n",
    "    merged = Dense(params['num_dense'], activation='relu')(merged)\n",
    "    merged = Dropout(params['dense_dropout_rate'])(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=[sequence_1_input, sequence_2_input],\n",
    "        outputs=output\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss=contrastive_loss,\n",
    "        optimizer='nadam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X_q1, X_q2):\n",
    "    \"\"\"\n",
    "    Mirror the pairs, compute two separate predictions, and average them.\n",
    "    \"\"\"\n",
    "    \n",
    "    y1 = model.predict([X_q1, X_q2], batch_size=1024, verbose=1).reshape(-1)   \n",
    "    y2 = model.predict([X_q2, X_q1], batch_size=1024, verbose=1).reshape(-1)    \n",
    "    return (y1 + y2) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(\n",
    "    n_splits=NUM_FOLDS,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create placeholders for out-of-fold predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_oofp = np.zeros_like(y_train, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_oofp = np.zeros((len(X_test_q1), NUM_FOLDS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best values picked by Bayesian optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'dense_dropout_rate': 0.164,\n",
    "    'lstm_dropout_rate': 0.324,\n",
    "    'num_dense': 50,\n",
    "    'num_lstm': 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path where the best weights of the current model will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_path = 'lstm.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the folds and compute out-of-fold predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting fold 1 of 2\n",
      "\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/1\n",
      "200000/200000 [==============================] - 918s 5ms/step - loss: 0.2410 - acc: 0.6096 - val_loss: 0.2085 - val_acc: 0.6735\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20851, saving model to lstm.h5\n",
      "100000/100000 [==============================] - 95s 949us/step\n",
      "100000/100000 [==============================] - 101s 1ms/step\n",
      "2345796/2345796 [==============================] - 2260s 964us/step\n",
      "2345796/2345796 [==============================] - 2274s 969us/step\n",
      "\n",
      "Fitting fold 2 of 2\n",
      "\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/1\n",
      " 11264/200000 [>.............................] - ETA: 12:01 - loss: 0.2968 - acc: 0.5112"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Iterate through folds.\n",
    "for fold_num, (ix_train, ix_val) in enumerate(kfold.split(X_train_q1, y_train)):\n",
    "    \n",
    "    # Augment the training set by mirroring the pairs.\n",
    "    X_fold_train_q1 = np.vstack([X_train_q1[ix_train], X_train_q2[ix_train]])\n",
    "    X_fold_train_q2 = np.vstack([X_train_q2[ix_train], X_train_q1[ix_train]])\n",
    "\n",
    "    X_fold_val_q1 = np.vstack([X_train_q1[ix_val], X_train_q2[ix_val]])\n",
    "    X_fold_val_q2 = np.vstack([X_train_q2[ix_val], X_train_q1[ix_val]])\n",
    "\n",
    "    # Ground truth should also be \"mirrored\".\n",
    "    y_fold_train = np.concatenate([y_train[ix_train], y_train[ix_train]])\n",
    "    y_fold_val = np.concatenate([y_train[ix_val], y_train[ix_val]])\n",
    "    \n",
    "    print()\n",
    "    print(f'Fitting fold {fold_num + 1} of {kfold.n_splits}')\n",
    "    print()\n",
    "    \n",
    "    # Compile a new model.\n",
    "    model = create_model(model_params)\n",
    "\n",
    "    # Train.\n",
    "    model.fit(\n",
    "        [X_fold_train_q1, X_fold_train_q2], y_fold_train,\n",
    "        validation_data=([X_fold_val_q1, X_fold_val_q2], y_fold_val),\n",
    "\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=MAX_EPOCHS,\n",
    "        verbose=1,\n",
    "        \n",
    "        callbacks=[\n",
    "            # Stop training when the validation loss stops improving.\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.001,\n",
    "                patience=3,\n",
    "                verbose=1,\n",
    "                mode='auto',\n",
    "            ),\n",
    "            # Save the weights of the best epoch.\n",
    "            ModelCheckpoint(\n",
    "                model_checkpoint_path,\n",
    "                monitor='val_loss',\n",
    "                save_best_only=True,\n",
    "                verbose=2,\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "        \n",
    "    # Restore the best epoch.\n",
    "    model.load_weights(model_checkpoint_path)\n",
    "    \n",
    "    # Compute out-of-fold predictions.\n",
    "    y_train_oofp[ix_val] = predict(model, X_train_q1[ix_val], X_train_q2[ix_val])\n",
    "    y_test_oofp[:, fold_num] = predict(model, X_test_q1, X_test_q2)\n",
    "    \n",
    "#     # Clear GPU memory.\n",
    "#     K.clear_session()\n",
    "#     del X_fold_train_q1\n",
    "#     del X_fold_train_q2\n",
    "#     del X_fold_val_q1\n",
    "#     del X_fold_val_q2\n",
    "#     del model\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 6.69816662880786\n"
     ]
    }
   ],
   "source": [
    "cv_score = log_loss(y_train, y_train_oofp)\n",
    "print('CV score:', cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_train = y_train_oofp.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404290/404290 [==============================] - 395s 976us/step\n",
      "404290/404290 [==============================] - 364s 900us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.31492162],\n",
       "       [0.28726369],\n",
       "       [0.        ],\n",
       "       ...,\n",
       "       [0.        ],\n",
       "       [0.36620432],\n",
       "       [0.28498039]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pickle.load(open('tokenized_train.csv', 'rb'))\n",
    "\n",
    "X_train_q1 = get_padded_index_sequence(\n",
    "    df['question1'].str.split(' ').tolist(), \n",
    "    w2v_model, \n",
    "    0, \n",
    "    max_string_length\n",
    ")\n",
    "\n",
    "X_train_q2 = get_padded_index_sequence(\n",
    "    df['question2'].str.split(' ').tolist(), \n",
    "    w2v_model, \n",
    "    0, \n",
    "    max_string_length\n",
    ")\n",
    "\n",
    "y_train_full = predict(model, X_train_q1, X_train_q2)\n",
    "features_train = y_train_full.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data=features_train,\n",
    "    index=df.index,\n",
    "    columns=['LSTM_PRED']\n",
    ").to_csv('../Datasets/FEATURE_lstm_pred_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 199680/2345796 [=>............................] - ETA: 36:24"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-e53ad90173de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# features_test = np.mean(y_test_oofp, axis=1).reshape((-1, 1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_test_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_q1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_q2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfeatures_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-68f8f46244db>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, X_q1, X_q2)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_q1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_q2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_q2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_q1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# features_test = np.mean(y_test_oofp, axis=1).reshape((-1, 1))\n",
    "y_test_full = predict(model, X_test_q1, X_test_q2)\n",
    "features_test = y_test_full.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20001793, 0.26233265, 0.44250882, ..., 0.22448152, 0.08923142,\n",
       "       0.29962581])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_oofp[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data=y_test_oofp[:, 0],\n",
    "    index=test_df.index,\n",
    "    columns=['LSTM_PRED']\n",
    ").to_csv('../Datasets/FEATURE_lstm_pred_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(\n",
    "    data=y_test_oofp[:, 0],\n",
    "    index=test_df.index,\n",
    "    columns=['is_duplicate']\n",
    ")\n",
    "submission.index.name = 'test_id'\n",
    "submission.reset_index(inplace=True)\n",
    "\n",
    "def recalibrate_prediction(pred, train_pos_ratio=0.3692, test_pos_ratio=0.165):\n",
    "    a = test_pos_ratio / train_pos_ratio\n",
    "    b = (1 - test_pos_ratio) / (1 - train_pos_ratio)\n",
    "    return a * pred / (a * pred + b * (1 - pred))\n",
    "\n",
    "submission['is_duplicate'] = submission['is_duplicate'].map(recalibrate_prediction)\n",
    "submission.to_csv('../Model_Build/lstm_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.077843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.107195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.211347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.164383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.210181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test_id  is_duplicate\n",
       "0       0      0.077843\n",
       "1       1      0.107195\n",
       "2       2      0.211347\n",
       "3       3      0.164383\n",
       "4       4      0.210181"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train: (200000, 1)\n",
      "X test:  (2345796, 1)\n"
     ]
    }
   ],
   "source": [
    "print('X train:', features_train.shape)\n",
    "print('X test: ', features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a701db828>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(features_test).plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
